{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project 4: SafeComm Digital Security Solutions</h1>\n",
    "<p>Team Captain: E00020</p>\n",
    "<p>Member 2: E00491</p>\n",
    "<p>Member 3: E00045</p>\n",
    "</br></br>\n",
    "<h2>Table of Contents</h2>\n",
    "<ol>\n",
    "  <li><a href=\"#section1\">Setup</a></li>\n",
    "  <li><a href=\"#section2\">EDA</a></li>\n",
    "  <li><a href=\"#section3\">Data Preprocessing</a></li>\n",
    "  <li><a href=\"#section4\">Models</a></li>\n",
    "  <li><a href=\"#section5\">Testing</a></li>\n",
    "</ol>\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"section1\">Setup</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessarylibaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "# import spacy\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# from textblob import TextBlob\n",
    "# from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# importing the csv into a pandas data frame\n",
    "df = pd.read_csv(\"./sms.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"section2\">Exploratory Data Analysis<h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraudolent</th>\n",
       "      <th>SMS test</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date and Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Squeeeeeze!! This is christmas hug.. If u lik ...</td>\n",
       "      <td>1EWYRBL</td>\n",
       "      <td>2017-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>And also I've sorta blown him off a couple tim...</td>\n",
       "      <td>ZY4PDK7</td>\n",
       "      <td>2018-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mmm thats better now i got a roast down me! i...</td>\n",
       "      <td>KLUX2C6</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>955HXJ0</td>\n",
       "      <td>2018-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>So there's a ring that comes with the guys cos...</td>\n",
       "      <td>00Q6EUC</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraudolent                                           SMS test       ID  \\\n",
       "0           0  Squeeeeeze!! This is christmas hug.. If u lik ...  1EWYRBL   \n",
       "1           0  And also I've sorta blown him off a couple tim...  ZY4PDK7   \n",
       "2           0  Mmm thats better now i got a roast down me! i...  KLUX2C6   \n",
       "3           0      Mm have some kanji dont eat anything heavy ok  955HXJ0   \n",
       "4           0  So there's a ring that comes with the guys cos...  00Q6EUC   \n",
       "\n",
       "  Date and Time  \n",
       "0    2017-12-02  \n",
       "1    2018-03-23  \n",
       "2    2016-10-29  \n",
       "3    2018-04-12  \n",
       "4    2016-08-01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraudolent\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "#sentiment count\n",
    "df['Fraudolent'].value_counts()\n",
    "# We have an "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 id=\"section3\">Data Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4) (572, 4)\n"
     ]
    }
   ],
   "source": [
    "# Divide train and test data\n",
    "TRAIN_TEST_SPLIT = 5000\n",
    "\n",
    "#train dataset\n",
    "train_df=df[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "#test dataset\n",
    "test_df=df[TRAIN_TEST_SPLIT:]\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\feder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#download the stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "#apply function on review column\n",
    "train_df['SMS test']=train_df['SMS test'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraudolent</th>\n",
       "      <th>SMS test</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date and Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Squeeeeeze This is christmas hug If u lik my f...</td>\n",
       "      <td>1EWYRBL</td>\n",
       "      <td>2017-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>And also Ive sorta blown him off a couple time...</td>\n",
       "      <td>ZY4PDK7</td>\n",
       "      <td>2018-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mmm thats better now i got a roast down me id ...</td>\n",
       "      <td>KLUX2C6</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>955HXJ0</td>\n",
       "      <td>2018-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>So theres a ring that comes with the guys cost...</td>\n",
       "      <td>00Q6EUC</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Todays the day if you are ready Im hor...</td>\n",
       "      <td>V3ISGBJ</td>\n",
       "      <td>2018-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>Jay told me already will do</td>\n",
       "      <td>4P5PPUR</td>\n",
       "      <td>2016-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>08714712388 between 10am7pm Cost 10p</td>\n",
       "      <td>1S89JLP</td>\n",
       "      <td>2016-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>Im good Have you registered to vote</td>\n",
       "      <td>C9CNU4L</td>\n",
       "      <td>2017-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>Goodmorning today i am late for 2hrs Because o...</td>\n",
       "      <td>8Y8V6GY</td>\n",
       "      <td>2018-06-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fraudolent                                           SMS test       ID  \\\n",
       "0              0  Squeeeeeze This is christmas hug If u lik my f...  1EWYRBL   \n",
       "1              0  And also Ive sorta blown him off a couple time...  ZY4PDK7   \n",
       "2              0  Mmm thats better now i got a roast down me id ...  KLUX2C6   \n",
       "3              0      Mm have some kanji dont eat anything heavy ok  955HXJ0   \n",
       "4              0  So theres a ring that comes with the guys cost...  00Q6EUC   \n",
       "...          ...                                                ...      ...   \n",
       "4995           1  FreeMsg Todays the day if you are ready Im hor...  V3ISGBJ   \n",
       "4996           0                        Jay told me already will do  4P5PPUR   \n",
       "4997           1               08714712388 between 10am7pm Cost 10p  1S89JLP   \n",
       "4998           0                Im good Have you registered to vote  C9CNU4L   \n",
       "4999           0  Goodmorning today i am late for 2hrs Because o...  8Y8V6GY   \n",
       "\n",
       "     Date and Time  \n",
       "0       2017-12-02  \n",
       "1       2018-03-23  \n",
       "2       2016-10-29  \n",
       "3       2018-04-12  \n",
       "4       2016-08-01  \n",
       "...            ...  \n",
       "4995    2018-04-27  \n",
       "4996    2016-12-10  \n",
       "4997    2016-05-19  \n",
       "4998    2017-01-19  \n",
       "4999    2018-06-16  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "#apply function on review column\n",
    "train_df['SMS test']=train_df['SMS test'].apply(remove_special_characters)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraudolent</th>\n",
       "      <th>SMS test</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date and Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>squeeeeez thi is christma hug if u lik my frnd...</td>\n",
       "      <td>1EWYRBL</td>\n",
       "      <td>2017-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>and also ive sorta blown him off a coupl time ...</td>\n",
       "      <td>ZY4PDK7</td>\n",
       "      <td>2018-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mmm that better now i got a roast down me id b...</td>\n",
       "      <td>KLUX2C6</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mm have some kanji dont eat anyth heavi ok</td>\n",
       "      <td>955HXJ0</td>\n",
       "      <td>2018-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>so there a ring that come with the guy costum ...</td>\n",
       "      <td>00Q6EUC</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg today the day if you are readi im horn...</td>\n",
       "      <td>V3ISGBJ</td>\n",
       "      <td>2018-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>jay told me alreadi will do</td>\n",
       "      <td>4P5PPUR</td>\n",
       "      <td>2016-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>08714712388 between 10am7pm cost 10p</td>\n",
       "      <td>1S89JLP</td>\n",
       "      <td>2016-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>im good have you regist to vote</td>\n",
       "      <td>C9CNU4L</td>\n",
       "      <td>2017-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>goodmorn today i am late for 2hr becaus of bac...</td>\n",
       "      <td>8Y8V6GY</td>\n",
       "      <td>2018-06-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fraudolent                                           SMS test       ID  \\\n",
       "0              0  squeeeeez thi is christma hug if u lik my frnd...  1EWYRBL   \n",
       "1              0  and also ive sorta blown him off a coupl time ...  ZY4PDK7   \n",
       "2              0  mmm that better now i got a roast down me id b...  KLUX2C6   \n",
       "3              0         mm have some kanji dont eat anyth heavi ok  955HXJ0   \n",
       "4              0  so there a ring that come with the guy costum ...  00Q6EUC   \n",
       "...          ...                                                ...      ...   \n",
       "4995           1  freemsg today the day if you are readi im horn...  V3ISGBJ   \n",
       "4996           0                        jay told me alreadi will do  4P5PPUR   \n",
       "4997           1               08714712388 between 10am7pm cost 10p  1S89JLP   \n",
       "4998           0                    im good have you regist to vote  C9CNU4L   \n",
       "4999           0  goodmorn today i am late for 2hr becaus of bac...  8Y8V6GY   \n",
       "\n",
       "     Date and Time  \n",
       "0       2017-12-02  \n",
       "1       2018-03-23  \n",
       "2       2016-10-29  \n",
       "3       2018-04-12  \n",
       "4       2016-08-01  \n",
       "...            ...  \n",
       "4995    2018-04-27  \n",
       "4996    2016-12-10  \n",
       "4997    2016-05-19  \n",
       "4998    2017-01-19  \n",
       "4999    2018-06-16  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "#apply function on review column\n",
    "train_df['SMS test']=train_df['SMS test'].apply(simple_stemmer)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "We should evaluate if it's useful because it can eliminate looots of words in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how', 'this', 'am', 'our', 'because', \"don't\", \"won't\", 'them', 'isn', 'to', \"wouldn't\", 'has', 'there', 's', 'won', 'same', 'that', 'we', 'again', 'of', \"you'd\", 'from', 'once', 'mightn', 'be', \"that'll\", 'yours', 'wasn', 'so', 'if', 'as', 'too', 'should', 'they', 'its', 'any', 'ourselves', 'about', 'not', 'can', 'is', 'are', 'only', 'under', 'both', \"weren't\", 'hadn', 'where', 'theirs', 'himself', 'had', 'until', 'it', 'needn', 'each', \"you're\", 'didn', 'an', 'her', 'you', 'what', 'will', 'very', 'nor', 'out', \"shouldn't\", 'aren', 'between', 'shouldn', 'o', 'weren', 'with', 'when', 'themselves', 'and', 'off', 'against', 'most', 'mustn', 'd', 'having', 'just', 'by', 'shan', 'at', 'all', 'down', 'she', 'before', 'ain', 'which', 'who', 'on', 'some', \"doesn't\", 'then', 'herself', \"you've\", 'after', 'than', 'were', \"mightn't\", 'haven', 'more', 'myself', 'your', 'further', 'a', 'he', 'hasn', \"she's\", 'll', 'below', 'few', 'have', 'doing', 'y', 'while', 'me', \"aren't\", \"haven't\", 'now', 'yourself', 'being', \"hasn't\", 'yourselves', 'hers', 'ours', 'their', \"it's\", 'couldn', 'such', 'don', 'whom', 'up', \"isn't\", \"didn't\", 'itself', 'the', 'but', 'him', 've', 'through', 're', \"couldn't\", 'over', \"you'll\", 'those', 'i', 'why', 't', 'been', \"mustn't\", 'into', 'doesn', 'was', 'own', 'these', 'does', 'ma', 'no', 'above', 'or', \"should've\", \"needn't\", 'in', 'other', \"hadn't\", 'his', 'did', 'during', 'do', \"wasn't\", 'for', \"shan't\", 'wouldn', 'here', 'my', 'm'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraudolent</th>\n",
       "      <th>SMS test</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date and Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>squeeeeez thi christma hug u lik frndshp den h...</td>\n",
       "      <td>1EWYRBL</td>\n",
       "      <td>2017-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>also ive sorta blown coupl time recent id rath...</td>\n",
       "      <td>ZY4PDK7</td>\n",
       "      <td>2018-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mmm better got roast id b better drink 2 good ...</td>\n",
       "      <td>KLUX2C6</td>\n",
       "      <td>2016-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mm kanji dont eat anyth heavi ok</td>\n",
       "      <td>955HXJ0</td>\n",
       "      <td>2018-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ring come guy costum gift futur yowif hint hint</td>\n",
       "      <td>00Q6EUC</td>\n",
       "      <td>2016-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg today day readi im horni live town lov...</td>\n",
       "      <td>V3ISGBJ</td>\n",
       "      <td>2018-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>jay told alreadi</td>\n",
       "      <td>4P5PPUR</td>\n",
       "      <td>2016-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "      <td>08714712388 10am7pm cost 10p</td>\n",
       "      <td>1S89JLP</td>\n",
       "      <td>2016-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>im good regist vote</td>\n",
       "      <td>C9CNU4L</td>\n",
       "      <td>2017-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>goodmorn today late 2hr becaus back pain</td>\n",
       "      <td>8Y8V6GY</td>\n",
       "      <td>2018-06-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fraudolent                                           SMS test       ID  \\\n",
       "0              0  squeeeeez thi christma hug u lik frndshp den h...  1EWYRBL   \n",
       "1              0  also ive sorta blown coupl time recent id rath...  ZY4PDK7   \n",
       "2              0  mmm better got roast id b better drink 2 good ...  KLUX2C6   \n",
       "3              0                   mm kanji dont eat anyth heavi ok  955HXJ0   \n",
       "4              0    ring come guy costum gift futur yowif hint hint  00Q6EUC   \n",
       "...          ...                                                ...      ...   \n",
       "4995           1  freemsg today day readi im horni live town lov...  V3ISGBJ   \n",
       "4996           0                                   jay told alreadi  4P5PPUR   \n",
       "4997           1                       08714712388 10am7pm cost 10p  1S89JLP   \n",
       "4998           0                                im good regist vote  C9CNU4L   \n",
       "4999           0           goodmorn today late 2hr becaus back pain  8Y8V6GY   \n",
       "\n",
       "     Date and Time  \n",
       "0       2017-12-02  \n",
       "1       2018-03-23  \n",
       "2       2016-10-29  \n",
       "3       2018-04-12  \n",
       "4       2016-08-01  \n",
       "...            ...  \n",
       "4995    2018-04-27  \n",
       "4996    2016-12-10  \n",
       "4997    2016-05-19  \n",
       "4998    2017-01-19  \n",
       "4999    2018-06-16  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "#apply function on review column\n",
    "train_df['SMS test']=train_df['SMS test'].apply(remove_stopwords)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text to numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0.0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "\n",
    "#transformed train reviews\n",
    "numerical_train_df=tv.fit_transform(train_df)\n",
    "print(type(numerical_train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.to_numpy of 0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    0\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: Fraudolent, Length: 5572, dtype: int64>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_column = df[\"Fraudolent\"]\n",
    "spam_column.to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 id=\"section4\">Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 5572]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\LUISS\\AI\\Project\\ai_safecom\\main.ipynb Cell 24\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/LUISS/AI/Project/ai_safecom/main.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lr\u001b[39m=\u001b[39mLogisticRegression(penalty\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m,max_iter\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,C\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/LUISS/AI/Project/ai_safecom/main.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#Fitting the model for tfidf features\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/LUISS/AI/Project/ai_safecom/main.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lr_tfidf\u001b[39m=\u001b[39mlr\u001b[39m.\u001b[39;49mfit(numerical_train_df,spam_column)\n",
      "File \u001b[1;32mc:\\Users\\feder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\feder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1208\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[0;32m   1211\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1212\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1213\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[0;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\feder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\feder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\feder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 5572]"
     ]
    }
   ],
   "source": [
    "# model 1 \n",
    "# Logistic Regression\n",
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(numerical_train_df,spam_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"section5\">Testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt run tests in seperate file?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
